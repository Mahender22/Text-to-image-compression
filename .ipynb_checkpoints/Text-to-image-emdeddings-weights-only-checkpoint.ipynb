{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7359293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8396befa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label                                         image_data\n",
      "0  0_11.png  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...\n",
      "1  1_25.png  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...\n",
      "2  2_42.png  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...\n",
      "3  3_15.png  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...\n",
      "4  4_56.png  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...\n"
     ]
    }
   ],
   "source": [
    "project_path = r'C:\\Users\\Mahender\\Documents\\MS docs\\Final docs\\Rowan University\\sem4\\ADV topics in DS LLM\\Project\\Text-to-image-for-compression'\n",
    "\n",
    "# 10 images 0 to 9 - 1 each\n",
    "img_path = project_path + r'\\\\Data\\Data-10-images'\n",
    "model_name = 'nn-10-0to9.h5'\n",
    "grayscale_path = img_path + '-gray'\n",
    "\n",
    "# # 10 images of 1\n",
    "# img_path = r'C:\\Users\\Mahender\\Documents\\MS docs\\Final docs\\Rowan University\\sem4\\ADV topics in DS LLM\\Project\\Text-to-image-for-compression\\Data\\Data-10-images-1'\n",
    "# model_name = 'nn-10-1.h5'\n",
    "# grayscale_path = img_path + '-gray'\n",
    "\n",
    "# # All images of 1 - 10772 images\n",
    "# img_path = r'C:\\Users\\Mahender\\Documents\\MS docs\\Final docs\\Rowan University\\sem4\\ADV topics in DS LLM\\Project\\Text-to-image-for-compression\\Data\\dataset\\1\\1'\n",
    "# model_name = 'nn-all-1.h5'\n",
    "# grayscale_path = img_path + '-gray'\n",
    "\n",
    "# # All images 0 to 9 - 118503 images\n",
    "# img_path = r'C:\\Users\\Mahender\\Documents\\MS docs\\Final docs\\Rowan University\\sem4\\ADV topics in DS LLM\\Project\\Text-to-image-for-compression\\Data\\Data-all-images'\n",
    "# model_name = 'nn-all.h5'\n",
    "# grayscale_path = img_path + '-gray'\n",
    "\n",
    "\n",
    "model_save_path = r'C:\\Users\\Mahender\\Documents\\MS docs\\Final docs\\Rowan University\\sem4\\ADV topics in DS LLM\\Project\\Text-to-image-for-compression'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(grayscale_path):\n",
    "    os.makedirs(grayscale_path)\n",
    "\n",
    "image_extension = '.png'\n",
    "\n",
    "data = []\n",
    "\n",
    "# Loop through all directories and subdirectories\n",
    "for root, dirs, files in os.walk(img_path):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(image_extension):\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                img = Image.open(file_path)\n",
    "                \n",
    "                # If the image is in RGBA, convert transparent pixels to white\n",
    "                if img.mode == 'RGBA':\n",
    "                    white_bg = Image.new('RGB', img.size, (255, 255, 255))\n",
    "                    white_bg.paste(img, mask=img.split()[3])\n",
    "                    # Convert the image to grayscale (L mode)\n",
    "                    img = white_bg.convert('L')\n",
    "                else:\n",
    "                    # If the image is already grayscale or RGB, just convert it to grayscale\n",
    "                    img = img.convert('L')\n",
    "                \n",
    "                # Convert image to numpy array and save to DataFrame\n",
    "                img_data = np.array(img)\n",
    "                label = file_path.split('\\\\')[-1]\n",
    "                data.append({\"label\": label, \"image_data\": img_data})\n",
    "\n",
    "                # Save the converted grayscale image\n",
    "                save_path = os.path.join(grayscale_path, file)\n",
    "                img.save(save_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error opening {file_path}: {e}\")\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b2cc52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract labels from the dataframe\n",
    "labels = df['label'].values\n",
    "\n",
    "# Convert the labels to integer encoding\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db2525ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming all images are grayscale and of size\n",
    "X = df['image_data'].values\n",
    "\n",
    "# Normalize pixel values\n",
    "X = np.array([x.flatten() / 255.0 for x in X])  # Flatten the images and normalize pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73ac8556",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Set embedding size to the square root of the number of labels\u001b[39;00m\n\u001b[0;32m     18\u001b[0m embedding_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39msqrt(num_labels))\n\u001b[1;32m---> 20\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model(input_dim, output_dim)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[0;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_dim' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the model with an Embedding layer\n",
    "def create_model(num_labels, output_dim, embedding_dim):\n",
    "    model = models.Sequential()\n",
    "    # Embedding layer: Takes integer-encoded labels and maps to dense vectors (embeddings)\n",
    "    model.add(layers.Embedding(input_dim=num_labels, output_dim=embedding_dim, input_length=1))\n",
    "    # Flatten the embedding output to pass to the next layer\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(32, activation='relu'))      \n",
    "    # Output layer (flattened image)\n",
    "    model.add(layers.Dense(output_dim, activation='sigmoid'))  # Output should be flattened to match image size\n",
    "    \n",
    "    return model\n",
    "\n",
    "# integer_encoded has shape (num_samples,)\n",
    "num_labels = len(np.unique(integer_encoded))  # Total number of unique labels\n",
    "output_dim = 28 * 28\n",
    "# Set embedding size to the square root of the number of labels\n",
    "embedding_dim = int(np.sqrt(num_labels))\n",
    "\n",
    "# Create the model\n",
    "model = create_model(num_labels, output_dim, embedding_dim)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40741b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(onehot_encoded, X, epochs=1200, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfd8369",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(model_save_path + '\\\\saved_embedded_weights\\\\' + model_name) # save weights only\n",
    "\n",
    "# Save the architecture\n",
    "model_json = model.to_json()\n",
    "with open(model_save_path + '\\\\saved_architecture\\\\embeddings_weights', \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d05ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model('\\\\nn-10-1.h5')\n",
    "\n",
    "# Load the architecture from the file\n",
    "from keras.models import model_from_json\n",
    "with open(model_save_path + '\\\\saved_architecture\\\\embeddings_weights', \"r\") as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    \n",
    "# Load the weights into the new model\n",
    "model.load_weights(model_save_path + '\\\\saved_embedded_weights\\\\' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e55c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model (necessary if you're going to use it for training or evaluation)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a3ec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c78c5e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pixel_accuracy(original, predicted):\n",
    "    \"\"\"\n",
    "    Calculate pixel accuracy based on the mean absolute error between the original and predicted images.\n",
    "\n",
    "    Parameters:\n",
    "    original (np.array): The original image array (shape: height x width).\n",
    "    predicted (np.array): The predicted image array (shape: height x width).\n",
    "\n",
    "    Returns:\n",
    "    float: The pixel accuracy as a percentage.\n",
    "    \"\"\"\n",
    "    original = np.array(original)\n",
    "    predicted = np.array(predicted)\n",
    "    \n",
    "    # Check if the shapes match\n",
    "    if original.shape != predicted.shape:\n",
    "        raise ValueError(\"Original and predicted images must have the same shape.\")\n",
    "    \n",
    "    # Calculate the mean absolute error\n",
    "    mae = np.mean(np.abs(original - predicted))\n",
    "\n",
    "    # Convert MAE to a percentage accuracy (assuming pixel values are in [0, 255])\n",
    "    max_mae = 255\n",
    "    accuracy = 100 * (1 - (mae / max_mae))  # Normalize accuracy to be between 0 and 100\n",
    "\n",
    "    return accuracy  # Return as percentage\n",
    "\n",
    "# Function to get the original image data from the DataFrame\n",
    "def get_original_image_from_df(label, df):\n",
    "    # Locate the row in the DataFrame that matches the label\n",
    "    row = df[df['label'] == label]\n",
    "    if not row.empty:\n",
    "        return row['image_data'].values[0]  # Get the image data\n",
    "    else:\n",
    "        print(\"Label not found in DataFrame.\")\n",
    "        return None\n",
    "\n",
    "# List to hold pixel accuracy values for all predictions\n",
    "all_accuracies = []\n",
    "\n",
    "# Make a prediction\n",
    "# labels_to_predict = df['label'].values\n",
    "labels_to_predict = random.sample(list(df['label'].values), 10)\n",
    "\n",
    "for label in labels_to_predict:\n",
    "    encoded_label = onehot_encoder.transform([[label_encoder.transform([label])[0]]])\n",
    "    predicted_image = model.predict(encoded_label)\n",
    "\n",
    "    # Reshape the predicted image and unnormalize it (convert back to 0-255 range)\n",
    "    predicted_image = predicted_image.reshape((28, 28))\n",
    "    predicted_image = predicted_image * 255.0  # Unnormalize the predicted image\n",
    "\n",
    "    # Get the original image from the DataFrame\n",
    "    original_image = get_original_image_from_df(label, df)\n",
    "\n",
    "    # Check if original image is not None\n",
    "    if original_image is not None:\n",
    "        # Calculate pixel accuracy\n",
    "        accuracy = pixel_accuracy(original_image, predicted_image)\n",
    "        all_accuracies.append(accuracy)\n",
    "        print(f\"Pixel Accuracy for label '{label}': {accuracy:.2f}%\")\n",
    "\n",
    "        # Set up the plot\n",
    "        plt.figure(figsize=(10, 5))\n",
    "\n",
    "        # Plot original image\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(original_image, cmap='gray')\n",
    "        plt.title('Original Image')\n",
    "        plt.axis('off')  # Hide axis\n",
    "\n",
    "        # Plot predicted image\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(predicted_image, cmap='gray')\n",
    "        plt.title('Predicted Image')\n",
    "        plt.axis('off')  # Hide axis\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "# Calculate and print the average pixel accuracy\n",
    "average_accuracy = np.mean(all_accuracies)\n",
    "print(f\"\\nAverage Pixel Accuracy over all above images: {average_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de3ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to hold pixel accuracy values for all predictions\n",
    "all_accuracies = []\n",
    "\n",
    "# Encode all labels in the DataFrame\n",
    "encoded_labels = onehot_encoder.transform([[label_encoder.transform([label])[0]] for label in df['label'].values])\n",
    "\n",
    "# Make predictions for all encoded labels at once\n",
    "predicted_images = model.predict(encoded_labels)\n",
    "\n",
    "# Loop over all predicted images and corresponding original images\n",
    "for i, label in enumerate(df['label'].values):\n",
    "    predicted_image = predicted_images[i].reshape((28, 28))  # Reshape the predicted image\n",
    "    predicted_image = predicted_image * 255.0  # Unnormalize the predicted image\n",
    "\n",
    "    # Get the original image from the DataFrame\n",
    "    original_image = get_original_image_from_df(label, df)\n",
    "\n",
    "    # Check if original image is not None\n",
    "    if original_image is not None:\n",
    "        # Calculate pixel accuracy\n",
    "        accuracy = pixel_accuracy(original_image, predicted_image)\n",
    "        all_accuracies.append(accuracy)\n",
    "\n",
    "# Calculate and print the average pixel accuracy\n",
    "if all_accuracies:\n",
    "    average_accuracy = np.mean(all_accuracies)\n",
    "    print(f\"\\nAverage Pixel Accuracy over all images: {average_accuracy:.2f}%\")\n",
    "else:\n",
    "    print(\"No valid images found for accuracy calculation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d455761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
